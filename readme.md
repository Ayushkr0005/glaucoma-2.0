# Glaucoma Detection System - Enhanced Edition

## Overview
An AI-powered Streamlit application for detecting glaucoma from retinal fundus images using deep learning. Features 17 models including 3 novel custom architectures (GlaucoNet, V2, V3) and 14 state-of-the-art pre-trained models, trained on the RFMID (Retinal Fundus Multi-Disease Image Dataset) from Kaggle.

## Recent Changes
- **2026-02-09**: Expanded to 17 models for comprehensive comparison
  - Added original GlaucoNet custom architecture
  - Added ResNet50, VGG16, VGG19, DenseNet121, DenseNet169
  - Added InceptionV3, Xception, MobileNetV2, EfficientNetB0, NASNetMobile
  - Created train_single.py for per-model training with memory management
  - Created run_training.sh for batch training all models
- **2026-02-05**: Major enhancement for publication-quality results
  - Switched to RFMID dataset from Kaggle for glaucoma detection
  - Created novel GlaucoNet-V2 architecture with CBAM attention and multi-scale ASPP features
  - Created GlaucoNet-V3 with hybrid CNN-Attention design
  - Implemented advanced data augmentation with MixUp and CutMix
  - Added Focal Loss and combined loss functions for class imbalance
  - Created comprehensive training pipeline with two-stage fine-tuning

## Project Architecture

### Directory Structure
```
glaucoma_detection/
â”œâ”€â”€ app.py                      # Main Streamlit entry point
â”œâ”€â”€ train_enhanced.py           # Enhanced training pipeline (all models)
â”œâ”€â”€ train_single.py             # Single model training script
â”œâ”€â”€ train_all.py                # Batch training orchestrator
â”œâ”€â”€ run_training.sh             # Shell script to train all models
â”œâ”€â”€ pages/                      # Streamlit multi-page structure
â”‚   â”œâ”€â”€ 1_ğŸ _Home.py           # Overview with RFMID dataset info
â”‚   â”œâ”€â”€ 2_ğŸ”¬_Prediction.py     # Image upload and prediction
â”‚   â”œâ”€â”€ 3_ğŸ“Š_Comparison.py     # Multi-model comparison
â”‚   â”œâ”€â”€ 4_ğŸ“ˆ_Analytics.py      # Performance dashboard
â”‚   â””â”€â”€ 5_â„¹ï¸_About.py          # Documentation
â”œâ”€â”€ src/                        # Source modules
â”‚   â”œâ”€â”€ models_enhanced.py      # All architectures (custom + pretrained)
â”‚   â”œâ”€â”€ data_pipeline.py        # Advanced data loading with augmentation
â”‚   â”œâ”€â”€ custom_model.py         # Original GlaucoNet architecture
â”‚   â”œâ”€â”€ evaluation.py           # Metrics and Grad-CAM visualization
â”‚   â””â”€â”€ utils.py                # Shared utilities (17 models)
â”œâ”€â”€ saved_models/               # Trained model files (.keras)
â”œâ”€â”€ results/                    # Training results
â”‚   â”œâ”€â”€ plots/                  # Training curves, confusion matrices
â”‚   â””â”€â”€ metrics/                # JSON metrics files
â””â”€â”€ data/rfmid/                 # RFMID dataset (ODC column for glaucoma)
    â”œâ”€â”€ Training_set/ (1920 images)
    â”œâ”€â”€ Validation_set/ (640 images)
    â””â”€â”€ Test_set/ (640 images)
```

### Novel Architectures

#### GlaucoNet (Original)
- Custom CNN with residual connections
- Squeeze-Excitation attention blocks
- Progressive feature extraction (32â†’64â†’128â†’256â†’512)

#### GlaucoNet-V2
- CBAM (Convolutional Block Attention Module) at multiple levels
- Multi-scale feature extraction using ASPP-style dilated convolutions
- Residual connections with GELU activation
- Dual global pooling (GAP + GMP)

#### GlaucoNet-V3
- Patch-like stem convolution (4x4 stride)
- Progressive feature extraction (48â†’96â†’192â†’384 channels)
- Squeeze-Excitation channel attention throughout
- CBAM spatial-channel attention
- Hybrid CNN-attention design with dual global pooling

### Models (17 Total)
| Model | Type | Input Size | Key Features |
|-------|------|------------|--------------|
| GlaucoNet | Custom | 224x224 | SE Attention + Residual |
| GlaucoNet_V2 | Custom | 224x224 | CBAM + ASPP + GELU |
| GlaucoNet_V3 | Custom | 224x224 | Hybrid + SE + CBAM |
| ResNet50 | Pretrained | 224x224 | Skip connections |
| ResNet50V2 | Pretrained | 224x224 | Pre-activation design |
| VGG16 | Pretrained | 224x224 | Classic 3x3 convolutions |
| VGG19 | Pretrained | 224x224 | Deeper VGG variant |
| DenseNet121 | Pretrained | 224x224 | Dense connections (compact) |
| DenseNet169 | Pretrained | 224x224 | Dense connections (medium) |
| DenseNet201 | Pretrained | 224x224 | Dense connections (deep) |
| InceptionV3 | Pretrained | 299x299 | Multi-scale features |
| Xception | Pretrained | 299x299 | Depthwise separable conv |
| MobileNetV2 | Pretrained | 224x224 | Inverted residuals |
| EfficientNetB0 | Pretrained | 224x224 | Compound scaling |
| EfficientNetV2S | Pretrained | 384x384 | Fused-MBConv |
| EfficientNetV2M | Pretrained | 480x480 | Best accuracy |
| NASNetMobile | Pretrained | 224x224 | NAS optimized |

### Dataset: RFMID
- Source: Kaggle (ozlemhakdagli/retinal-fundus-multi-disease-image-dataset-rfmid)
- Task: Binary classification (ODC - Optic Disc Cupping for Glaucoma)
- Training: 1920 images (1638 normal, 282 glaucoma)
- Validation: 640 images
- Test: 640 images
- Format: High-quality PNG fundus images

### Training Features
- Two-stage training: classifier head â†’ fine-tuning with unfreezing
- Advanced augmentation: MixUp, CutMix, CLAHE, Equalize
- Combined loss: Focal Loss + Binary Cross-Entropy
- AdamW optimizer with cosine annealing LR
- Class weighting for imbalanced data (3.4:1 ratio)
- K-fold cross-validation support

### Running the Application
```bash
streamlit run app.py --server.port 5000
```

### Training Models
```bash
# Train a single model
python train_single.py GlaucoNet 10 5

# Train all models
bash run_training.sh

# Train with original pipeline
python train_enhanced.py
```

### Severity Mapping
| Confidence | Severity | Est. CDR |
|------------|----------|----------|
| 0.0-0.3 | Normal | < 0.3 |
| 0.3-0.5 | Borderline | 0.3-0.5 |
| 0.5-0.7 | Early | 0.5-0.6 |
| 0.7-0.85 | Moderate | 0.6-0.7 |
| 0.85-0.95 | Severe | 0.7-0.9 |
| 0.95-1.0 | Critical | > 0.9 |

## Publication Notes
- 17 models for comprehensive comparison study
- 3 novel custom architectures designed for originality
- Comprehensive ablation studies supported
- Cross-validation for statistical significance
- Grad-CAM for interpretability
- All metrics logged for reproducibility

## User Preferences
- Clinical color scheme (white/blue background)
- Medical disclaimers on all predictions
- CDR values marked as estimates
